{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import datashader\n",
    "import bokeh\n",
    "import holoviews\n",
    "import umap\n",
    "import umap.plot\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import copy\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from sklearn.metrics import confusion_matrix as cm\n",
    "import glob2\n",
    "from pathlib import Path \n",
    "from sklearn.metrics import roc_curve\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.optimize import brentq\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils import tensorboard\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from model import StyleEncoder as Encoder \n",
    "from data_generator import CatsDataset\n",
    "from metrics import Accuracy\n",
    "\n",
    "umap.plot.output_notebook()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Train / Val / Test folders (One time use)\n",
    "\n",
    "root_dir = 'dataset'\n",
    "classes_dir = ['black', 'blackwhite', 'gray', 'siberian', 'siamese', 'ginger', 'gingerwhite', 'white', 'other']\n",
    "\n",
    "val_ratio = 0.2\n",
    "\n",
    "for cls in classes_dir:\n",
    "    os.makedirs(root_dir +'/train' + '/' + cls, exist_ok=True)\n",
    "    os.makedirs(root_dir +'/val' + '/' + cls, exist_ok=True)\n",
    "    \n",
    "    # Creating partitions of the data after shuffeling\n",
    "    src = root_dir + '/' + cls # Folder to copy images from\n",
    "    \n",
    "    allFileNames = os.listdir(src)\n",
    "    np.random.shuffle(allFileNames)\n",
    "    train_FileNames, val_FileNames = np.split(np.array(allFileNames), [int(len(allFileNames)* (1 - val_ratio))])\n",
    "    \n",
    "    train_FileNames = [src+'/'+ name for name in train_FileNames.tolist()]\n",
    "    val_FileNames = [src+'/' + name for name in val_FileNames.tolist()]\n",
    "    \n",
    "    print('Class: ' + cls)\n",
    "    print('Total images: ', len(allFileNames))\n",
    "    print('Training: ', len(train_FileNames))\n",
    "    print('Validation: ', len(val_FileNames))\n",
    "    print()\n",
    "    \n",
    "    # Copy-pasting images\n",
    "    for name in train_FileNames:\n",
    "        shutil.copy(name, root_dir +'/train/' + cls)\n",
    "        \n",
    "        new_path = root_dir +'/train/' + cls + '/' + name.split('/')[-1]\n",
    "        img = Image.open(new_path)\n",
    "        img = np.array(img)[:, 256:, :]\n",
    "        result = Image.fromarray((img).astype(np.uint8))\n",
    "        result.save(new_path)\n",
    "\n",
    "    for name in val_FileNames:\n",
    "        shutil.copy(name, root_dir +'/val/' + cls)\n",
    "        \n",
    "        new_path = root_dir +'/val/' + cls + '/' + name.split('/')[-1]\n",
    "        img = Image.open(new_path)\n",
    "        img = np.array(img)[:, 256:, :]\n",
    "        result = Image.fromarray((img).astype(np.uint8))\n",
    "        result.save(new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Help Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_training_curves(train_epochs, training, val_epochs, validation, title, subplot):\n",
    "    \"\"\"\n",
    "    Plots training and validation curves.\n",
    "    \"\"\"\n",
    "    \n",
    "    if subplot%10==1:\n",
    "        plt.subplots(figsize=(5,5), facecolor='#F0F0F0')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "    ax = plt.subplot(subplot)\n",
    "    ax.set_facecolor('#F8F8F8')\n",
    "    ax.plot(train_epochs, training)\n",
    "    ax.plot(val_epochs, validation)\n",
    "    ax.set_title('model '+ title)\n",
    "    ax.set_ylabel(title)\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.legend(['train', 'val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_similarity_matrix(matrix, labels_a=None, labels_b=None, ax: plt.Axes=None, title=\"\"):\n",
    "    \"\"\"\n",
    "    Plots similarity matrix.\n",
    "    \"\"\"\n",
    "    \n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots()\n",
    "    fig = plt.gcf()\n",
    "        \n",
    "    img = ax.matshow(matrix, extent=(-0.5, matrix.shape[0] - 0.5, \n",
    "                                     -0.5, matrix.shape[1] - 0.5))\n",
    "\n",
    "    ax.xaxis.set_ticks_position(\"bottom\")\n",
    "    if labels_a is not None:\n",
    "        ax.set_xticks(range(len(labels_a)))\n",
    "        ax.set_xticklabels(labels_a, rotation=90)\n",
    "    if labels_b is not None:\n",
    "        ax.set_yticks(range(len(labels_b)))\n",
    "        ax.set_yticklabels(labels_b[::-1])  # Upper origin -> reverse y axis\n",
    "    ax.set_title(title)\n",
    "\n",
    "    cax = make_axes_locatable(ax).append_axes(\"right\", size=\"5%\", pad=0.15)\n",
    "    fig.colorbar(img, cax=cax, ticks=np.linspace(0, 1, 7))\n",
    "    img.set_clim(0.4, 1)\n",
    "    img.set_cmap(\"inferno\")\n",
    "    \n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_cm(targets, predictions, num_classes):\n",
    "    \"\"\"\n",
    "    Plots confusion matrix.\n",
    "    \"\"\"\n",
    "    \n",
    "    cls_dict = {0: 'black',\n",
    "                1: 'blackwhite',\n",
    "                2: 'gray',\n",
    "                3: 'siberian',\n",
    "                4: 'siamese',\n",
    "                5: 'ginger',\n",
    "                6: 'gingerwhite',\n",
    "                7: 'white',\n",
    "                8: 'other',\n",
    "               }\n",
    "\n",
    "    confusion_matrix = cm(targets, predictions)\n",
    "    score = f1_score(targets, predictions, labels=range(num_classes), average='macro')\n",
    "    precision = precision_score(targets, predictions, labels=range(num_classes), average='macro')\n",
    "    recall = recall_score(targets, predictions, labels=range(num_classes), average='macro')\n",
    "\n",
    "    confusion_matrix = np.around(confusion_matrix.astype('float') / confusion_matrix.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "    confusion_matrix = pd.DataFrame(confusion_matrix,\n",
    "                                    index = cls_dict.values(), \n",
    "                                    columns = cls_dict.values())\n",
    "\n",
    "\n",
    "    figure = plt.figure(figsize=(7, 7))\n",
    "    sns.heatmap(confusion_matrix, annot=True,cmap=plt.cm.Blues)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "\n",
    "    print('f1 score: {:.3f}, precision: {:.3f}, recall: {:.3f}'.format(score, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(current_iter, optimizer, init_lr, gamma, list_of_iters):\n",
    "    \"\"\"\n",
    "    Learning rate scheduler. Performs exponentially decaying.\n",
    "    \n",
    "    :current_iter: int, number of current iteration\n",
    "    :optimizer: model optimizer\n",
    "    :init_lr: float, initial learning rate\n",
    "    :gamma: float, decay rate \n",
    "    :list_of_iters: list of ints, iteration numbers for decaying\n",
    "    \n",
    "    :return: float, current learning rate\n",
    "    \"\"\"\n",
    "    \n",
    "    current_lr = 0\n",
    "    power = 0\n",
    "    if current_iter < list_of_iters[0]:\n",
    "        current_lr = init_lr\n",
    "    elif current_iter > list_of_iters[-1]:\n",
    "        current_lr = init_lr * (gamma ** len(list_of_iters))\n",
    "    else:\n",
    "        list_of_iters.sort(reverse=True)\n",
    "        nearest_smaller_iter = min(list_of_iters, key=lambda x : x - current_iter > 0 )\n",
    "        list_of_iters.sort(reverse=False)\n",
    "        index_of_nearest_smaller_iter = list_of_iters.index(nearest_smaller_iter) \n",
    "        power = index_of_nearest_smaller_iter + 1\n",
    "        current_lr = init_lr * (gamma ** power)\n",
    "    \n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = current_lr\n",
    "\n",
    "    return current_lr\n",
    "\n",
    "\n",
    "def save_checkpoint(model, opt, name):\n",
    "    \"\"\"\n",
    "    Saves current model checkpoint.\n",
    "        \n",
    "    :model: model to save\n",
    "    :opt: optimizer\n",
    "    :name: str, name of model to save\n",
    "    \"\"\"\n",
    "    checkpoint = {\n",
    "        \"state_dict\": model.state_dict(),\n",
    "        \"optimizer\": opt.state_dict(),\n",
    "    }\n",
    "    torch.save(checkpoint, name)\n",
    "\n",
    "    \n",
    "def load_checkpoint(model, checkpoint_dir, optimizer=None):\n",
    "    \"\"\"\n",
    "    Loads model checkpoint.\n",
    "        \n",
    "    :model: model to save\n",
    "    :checkpoints_dir: str, path to the checkpoints\n",
    "    :optimizer: optimizer\n",
    "    \"\"\"\n",
    "    print(f\"Loading checkpoint...\")\n",
    "    checkpoint = torch.load(checkpoint_dir, map_location='cpu')\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    if optimizer is not None:\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "    print('Checkpoint was restored!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s = 5 \n",
    "m = 0.35\n",
    "emb_size = 256\n",
    "\n",
    "model = Encoder(init_channels=32, num_features=emb_size, \n",
    "                num_classes=9, dropout=0.4, s=s, m=m).to(device)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generator and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.001\n",
    "train_BATCH_SIZE = 64\n",
    "val_BATCH_SIZE = 1\n",
    "weight_decay = 1e-4\n",
    "\n",
    "train_path = glob2.glob('dataset/train/*/*.png')\n",
    "train_dataset = CatsDataset(train_path, augment=True)\n",
    "trainloader = DataLoader(train_dataset, batch_size=train_BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "\n",
    "val_path = glob2.glob('dataset/val/*/*.png')\n",
    "val_dataset = CatsDataset(val_path, augment=False)\n",
    "valloader = DataLoader(val_dataset, batch_size=val_BATCH_SIZE, shuffle=False, drop_last=True)\n",
    "\n",
    "checkpoint_path = Path('models')\n",
    "model_path = checkpoint_path.joinpath(f'model_s{s}_m{m}_emb{emb_size}.pth')\n",
    "\n",
    "accuracy = Accuracy()\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "params = []\n",
    "\n",
    "for name, values in model.named_parameters():\n",
    "    if 'bias' not in name and 'norm' not in name:\n",
    "        params += [{'params': [values], 'lr': initial_learning_rate, 'weight_decay': weight_decay}]\n",
    "    else:\n",
    "        params += [{'params': [values], 'lr': initial_learning_rate, 'weight_decay': 0.0}]\n",
    "        \n",
    "opt = optim.Adam(params, lr=initial_learning_rate, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "decay_steps=1000\n",
    "decay_rate=0.9\n",
    "all_steps = epochs * len(trainloader)\n",
    "\n",
    "list_of_iters = []\n",
    "decay_iter = 0\n",
    "\n",
    "while decay_iter <= all_steps:\n",
    "    decay_iter = decay_iter + decay_steps\n",
    "    list_of_iters.append(decay_iter)\n",
    "    \n",
    "print(list_of_iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train the model\n",
    "\n",
    "epochs = 1000\n",
    "\n",
    "train_steps = len(trainloader)\n",
    "val_steps = len(valloader)\n",
    "\n",
    "train_epoch_losses=[]\n",
    "val_epoch_losses=[]\n",
    "\n",
    "train_epoch_accuracy=[]\n",
    "val_epoch_accuracy=[]\n",
    "\n",
    "train_epochs=[]\n",
    "val_epochs=[]\n",
    "\n",
    "best_val_acc = -100\n",
    "best_epoch = 0\n",
    "last_saved_epoch = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    train_losses = []\n",
    "    train_accuracies =[]\n",
    "    \n",
    "    for image, label_idx, image_path in trainloader:\n",
    "    \n",
    "        image = image.to(device, dtype=torch.float)  \n",
    "        label_idx = label_idx.to(device)\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        model.train()\n",
    "        out, out_fcl = model(image, label_idx)\n",
    "        train_loss = loss(out, label_idx)\n",
    "        train_loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        train_accuracy = accuracy(out, label_idx)\n",
    "        train_losses.append(train_loss.item())\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        \n",
    "        step = model.get_step()\n",
    "        last_train_step = copy.deepcopy(step)\n",
    "        \n",
    "        current_lr = adjust_learning_rate(step, opt, initial_learning_rate, decay_rate, list_of_iters)\n",
    "        \n",
    "    train_epoch_losses.append(np.mean(train_losses))\n",
    "    train_epoch_accuracy.append(np.mean(train_accuracies))\n",
    "    train_epochs.append(epoch)\n",
    "    \n",
    "    msg = f\"| Epoch: {epoch}/{epochs} ({step}/{all_steps}) | Avg Loss: {np.mean(train_losses):#.4} | Avg Accuracy: {np.mean(train_accuracies):#.4} | LR: {current_lr:#.4} | \"\n",
    "    print(msg)\n",
    "    \n",
    "    if epoch % 1 ==0:\n",
    "        val_losses = []\n",
    "        val_accuracies =[]\n",
    "        for image, label_idx, image_path in valloader:\n",
    "            with torch.no_grad():\n",
    "                \n",
    "                image = image.to(device, dtype=torch.float)  \n",
    "                label_idx = label_idx.to(device)\n",
    "        \n",
    "                model.eval()\n",
    "                out, out_fcl = model(image, label_idx)\n",
    "                val_loss = loss(out, label_idx)\n",
    "                val_accuracy = accuracy(out, label_idx)\n",
    "                val_losses.append(val_loss.item())\n",
    "                val_accuracies.append(val_accuracy)\n",
    "\n",
    "        msg = f\"| Epoch: {epoch}/{epochs} | Eval Avg Loss: {np.mean(val_losses):#.4} | Eval Avg Accuracy: {np.mean(val_accuracies):#.4} | \"\n",
    "        print(msg)\n",
    "\n",
    "        val_epoch_losses.append(np.mean(val_losses))\n",
    "        val_epoch_accuracy.append(np.mean(val_accuracies))\n",
    "        val_epochs.append(epoch)\n",
    "\n",
    "        model.set_step(last_train_step)           \n",
    "        \n",
    "        if val_epoch_accuracy[-1]>=best_val_acc:\n",
    "            best_val_acc = val_epoch_accuracy[-1]\n",
    "            best_epoch=epoch\n",
    "            save_checkpoint(model, opt, model_path)\n",
    "            \n",
    "        if epoch - last_saved_epoch > 70:\n",
    "            break \n",
    "            \n",
    "        if val_epoch_accuracy[-1]>=best_val_acc:\n",
    "            last_saved_epoch = epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best epoch: ' + str(best_epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_training_curves(train_epochs, train_epoch_losses, val_epochs, val_epoch_losses, 'loss', 211)\n",
    "display_training_curves(train_epochs, train_epoch_accuracy, val_epochs, val_epoch_accuracy, 'accuracy', 212)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check validation accuracy\n",
    "\n",
    "model_inference = Encoder(init_channels=32, num_features=emb_size, \n",
    "                          num_classes=9, dropout=0.4, s=s, m=m).to(device)\n",
    "\n",
    "load_checkpoint(model=model_inference, checkpoint_dir=model_path)\n",
    "accuracy = Accuracy()\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "val_losses = []\n",
    "val_accuracies =[]\n",
    "\n",
    "for image, label_idx, image_path in valloader:\n",
    "    with torch.no_grad():\n",
    "                \n",
    "        image = image.to(device, dtype=torch.float)  \n",
    "        label_idx = label_idx.to(device)  \n",
    "        model_inference.eval()\n",
    "        \n",
    "        out, out_fcl = model_inference(image, label_idx)\n",
    "        \n",
    "        val_loss = loss(out, label_idx)\n",
    "        val_accuracy = accuracy(out, label_idx)\n",
    "        val_losses.append(val_loss.item())\n",
    "        val_accuracies.append(val_accuracy)  \n",
    "        \n",
    "print('Validation accuracy: ', np.mean(val_accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tune the model using a low learning rate\n",
    "\n",
    "initial_learning_rate = 1e-6\n",
    "train_BATCH_SIZE = 64\n",
    "val_BATCH_SIZE = 1\n",
    "weight_decay = 1e-4\n",
    "\n",
    "epochs = 1000\n",
    "decay_steps=500\n",
    "decay_rate=0.9\n",
    "all_steps = epochs * len(trainloader)\n",
    "\n",
    "list_of_iters = []\n",
    "decay_iter = 0\n",
    "\n",
    "while decay_iter <= all_steps:\n",
    "    decay_iter = decay_iter + decay_steps\n",
    "    list_of_iters.append(decay_iter)  \n",
    "    \n",
    "print(list_of_iters)\n",
    "\n",
    "model_tune = Encoder(init_channels=32, num_features=emb_size, num_classes=9, dropout=0.4, s=s, m=m).to(device)\n",
    "model_tune_path = checkpoint_path.joinpath(f'model_tune_s{s}_m{m}_emb{emb_size}.pth')\n",
    "\n",
    "params = []\n",
    "\n",
    "for name, values in model_tune.named_parameters():\n",
    "    if 'bias' not in name and 'norm' not in name:\n",
    "        params += [{'params': [values], 'lr': initial_learning_rate, 'weight_decay': weight_decay}]\n",
    "    else:\n",
    "        params += [{'params': [values], 'lr': initial_learning_rate, 'weight_decay': 0.0}]\n",
    "\n",
    "opt = optim.Adam(params, lr=initial_learning_rate, betas=(0.9, 0.999))\n",
    "load_checkpoint(model=model_tune, checkpoint_dir=model_path, optimizer=opt)\n",
    "        \n",
    "accuracy = Accuracy()\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "\n",
    "train_steps = len(trainloader)\n",
    "val_steps = len(valloader)\n",
    "\n",
    "train_epoch_losses=[]\n",
    "val_epoch_losses=[]\n",
    "\n",
    "train_epoch_accuracy=[]\n",
    "val_epoch_accuracy=[]\n",
    "\n",
    "train_epochs=[]\n",
    "val_epochs=[]\n",
    "\n",
    "best_val_acc = -100\n",
    "best_epoch = 0\n",
    "last_saved_epoch = 0\n",
    "\n",
    "model_tune.set_step(0)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    train_losses = []\n",
    "    train_accuracies =[]\n",
    "    \n",
    "    for image, label_idx, image_path in trainloader:\n",
    "    \n",
    "        image = image.to(device, dtype=torch.float)  \n",
    "        label_idx = label_idx.to(device)\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        model_tune.train()\n",
    "        out, out_fcl = model_tune(image, label_idx)\n",
    "        train_loss = loss(out, label_idx)\n",
    "        train_loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        train_accuracy = accuracy(out, label_idx)\n",
    "        train_losses.append(train_loss.item())\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        \n",
    "        step = model_tune.get_step()\n",
    "        last_train_step = copy.deepcopy(step)\n",
    "        \n",
    "        # get current learning rate \n",
    "        current_lr = adjust_learning_rate(step, opt, initial_learning_rate, decay_rate, list_of_iters)\n",
    "        \n",
    "    train_epoch_losses.append(np.mean(train_losses))\n",
    "    train_epoch_accuracy.append(np.mean(train_accuracies))\n",
    "    train_epochs.append(epoch)\n",
    "    \n",
    "    msg = f\"| Epoch: {epoch}/{epochs} ({step}/{all_steps}) | Avg Loss: {np.mean(train_losses):#.4} | Avg Accuracy: {np.mean(train_accuracies):#.4} | LR: {current_lr:#.4} | \"\n",
    "    print(msg)\n",
    "    \n",
    "    if epoch % 1 ==0:\n",
    "        val_losses = []\n",
    "        val_accuracies =[]\n",
    "        for image, label_idx, image_path in valloader:\n",
    "            with torch.no_grad():\n",
    "                \n",
    "                image = image.to(device, dtype=torch.float)  \n",
    "                label_idx = label_idx.to(device)\n",
    "        \n",
    "                model_tune.eval()\n",
    "                out, out_fcl = model_tune(image, label_idx)\n",
    "\n",
    "                val_loss = loss(out, label_idx)\n",
    "                val_accuracy = accuracy(out, label_idx)\n",
    "                val_losses.append(val_loss.item())\n",
    "                val_accuracies.append(val_accuracy)\n",
    "\n",
    "        msg = f\"| Epoch: {epoch}/{epochs} | Eval Avg Loss: {np.mean(val_losses):#.4} | Eval Avg Accuracy: {np.mean(val_accuracies):#.4} | \"\n",
    "        print(msg)\n",
    "\n",
    "        val_epoch_losses.append(np.mean(val_losses))\n",
    "        val_epoch_accuracy.append(np.mean(val_accuracies))\n",
    "        val_epochs.append(epoch)\n",
    "\n",
    "        model_tune.set_step(last_train_step)  \n",
    "            \n",
    "        if val_epoch_accuracy[-1]>=best_val_acc:\n",
    "            best_val_acc = val_epoch_accuracy[-1]\n",
    "            best_epoch=epoch\n",
    "            save_checkpoint(model_tune, opt, model_tune_path)\n",
    "            \n",
    "        if epoch - last_saved_epoch > 70:\n",
    "            break \n",
    "            \n",
    "        if val_epoch_accuracy[-1]>=best_val_acc:\n",
    "            last_saved_epoch = epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "display_training_curves(train_epochs, train_epoch_losses, val_epochs, val_epoch_losses, 'loss', 211)\n",
    "display_training_curves(train_epochs, train_epoch_accuracy, val_epochs, val_epoch_accuracy, 'accuracy', 212)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tune_inference = Encoder(init_channels=32, num_features=emb_size, \n",
    "                               num_classes=9, dropout=0.4, s=s, m=m).to(device)\n",
    "\n",
    "load_checkpoint(model=model_tune_inference, checkpoint_dir=model_tune_path)\n",
    "accuracy = Accuracy()\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "val_losses = []\n",
    "val_accuracies =[]\n",
    "\n",
    "for image, label_idx, image_path in valloader:\n",
    "    with torch.no_grad():\n",
    "                \n",
    "        image = image.to(device, dtype=torch.float)  \n",
    "        label_idx = label_idx.to(device)  \n",
    "        model_tune_inference.eval()\n",
    "        \n",
    "        out, out_fcl = model_tune_inference(image, label_idx)\n",
    "        \n",
    "        val_loss = loss(out, label_idx)\n",
    "        val_accuracy = accuracy(out, label_idx)\n",
    "        val_losses.append(val_loss.item())\n",
    "        val_accuracies.append(val_accuracy)  \n",
    "        \n",
    "np.mean(val_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### U-Map projection for validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaL_features = []\n",
    "vaL_labels = []\n",
    "paths_val = []\n",
    "\n",
    "for image, label_idx, image_path in valloader:\n",
    "    with torch.no_grad():    \n",
    "        \n",
    "        image = image.to(device, dtype=torch.float)  \n",
    "        label_idx = label_idx.to(device)\n",
    "        model_tune_inference.eval()\n",
    "        \n",
    "        out, out_fcl = model_tune_inference(image, label_idx)\n",
    "        out_fcl = out_fcl.cpu()\n",
    "        out_fcl =  out_fcl / np.linalg.norm(out_fcl, axis=1, keepdims=True)\n",
    "        \n",
    "        vaL_features.append(out_fcl[0, :].numpy())\n",
    "        vaL_labels.append(label_idx.item())\n",
    "        paths_val.append(image_path)\n",
    "\n",
    "val_hover_data = pd.DataFrame({'index':paths_val, 'label':vaL_labels})\n",
    "\n",
    "val_hover_data['item'] = val_hover_data.label.map({0: 'black_val',\n",
    "                                                   1: 'blackwhite_val',\n",
    "                                                   2: 'grey_val',\n",
    "                                                   3: 'siberian_val',\n",
    "                                                   4: 'siamese_val',\n",
    "                                                   5: 'ginger_val',\n",
    "                                                   6: 'gingerwhite_val',\n",
    "                                                   7: 'white_val',\n",
    "                                                   8: 'other_val'}\n",
    "                                                )        \n",
    "        \n",
    "vaL_features = np.array(vaL_features)\n",
    "vaL_labels = np.array(vaL_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "mapper = umap.UMAP(random_state=42, n_neighbors=10).fit(vaL_features)\n",
    "\n",
    "p = umap.plot.interactive(mapper, labels=vaL_labels, hover_data=val_hover_data, point_size=3, theme='fire')\n",
    "\n",
    "umap.plot.show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### U-Map projection for train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = glob2.glob('dataset/train/*/*.png')\n",
    "train_dataset = CatsDataset(train_path, augment=False)\n",
    "trainloader = DataLoader(train_dataset, batch_size=1, shuffle=False, drop_last=False)\n",
    "\n",
    "train_features = []\n",
    "train_labels = []\n",
    "paths_train = []\n",
    "\n",
    "for image, label_idx, image_path in trainloader:\n",
    "    with torch.no_grad():    \n",
    "        \n",
    "        image = image.to(device, dtype=torch.float)  \n",
    "        label_idx = label_idx.to(device)\n",
    "        model_tune_inference.eval()\n",
    "        \n",
    "        out, out_fcl = model_tune_inference(image, label_idx)\n",
    "        out_fcl = out_fcl.cpu()\n",
    "        out_fcl =  out_fcl / np.linalg.norm(out_fcl, axis=1, keepdims=True)\n",
    "        \n",
    "        train_features.append(out_fcl[0, :].numpy())\n",
    "        train_labels.append(label_idx.item())\n",
    "        paths_train.append(image_path)\n",
    "\n",
    "train_hover_data = pd.DataFrame({'index':paths_train, 'label':train_labels})\n",
    "train_hover_data['item'] = train_hover_data.label.map({0: 'black_train',\n",
    "                                                       1: 'blackwhite_train',\n",
    "                                                       2: 'grey_train',\n",
    "                                                       3: 'siberian_train',\n",
    "                                                       4: 'siamese_train',\n",
    "                                                       5: 'ginger_train',\n",
    "                                                       6: 'gingerwhite_train',\n",
    "                                                       7: 'white_train',\n",
    "                                                       8: 'other_train'}\n",
    "                                                    )         \n",
    "        \n",
    "train_features = np.array(train_features)\n",
    "train_labels = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = umap.UMAP(random_state=42, n_neighbors=10).fit(train_features)\n",
    "\n",
    "p = umap.plot.interactive(mapper, labels=train_labels, hover_data=train_hover_data, point_size=2, theme='fire')\n",
    "\n",
    "umap.plot.show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### U-Map projection for train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = np.concatenate((train_features, vaL_features))\n",
    "all_labels = np.concatenate((train_labels, vaL_labels))\n",
    "all_hover_data = pd.concat([train_hover_data, val_hover_data], axis=0, ignore_index=True)\n",
    "\n",
    "mapper = umap.UMAP(random_state=42, n_neighbors=10).fit(all_features)\n",
    "\n",
    "\n",
    "p = umap.plot.interactive(mapper, labels=all_labels, hover_data=all_hover_data, point_size=2, theme='fire')\n",
    "\n",
    "umap.plot.show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculation of the average embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "black_features = []\n",
    "black_white_features = []\n",
    "gray_features = []\n",
    "siberian_features = []\n",
    "siamese_features = []\n",
    "ginger_features =[]\n",
    "ginger_white_features = []\n",
    "white_features = []\n",
    "other_features = []\n",
    "\n",
    "for i in range(len(train_labels)):\n",
    "    label = train_labels[i]\n",
    "    train_feature = train_features[i]\n",
    "    \n",
    "    if label == 0:\n",
    "        black_features.append(train_feature)\n",
    "        \n",
    "    elif label == 1:\n",
    "        black_white_features.append(train_feature)\n",
    "        \n",
    "    elif label == 2:\n",
    "        gray_features.append(train_feature)\n",
    "        \n",
    "    elif label == 3:\n",
    "        siberian_features.append(train_feature)\n",
    "        \n",
    "    elif label == 4:\n",
    "        siamese_features.append(train_feature)\n",
    "        \n",
    "    elif label == 5:\n",
    "        ginger_features.append(train_feature)\n",
    "        \n",
    "    elif label == 6:  \n",
    "        ginger_white_features.append(train_feature)   \n",
    "        \n",
    "    elif label == 7:  \n",
    "        white_features.append(train_feature) \n",
    "        \n",
    "    elif label == 8:  \n",
    "        other_features.append(train_feature) \n",
    "\n",
    "avg_features = [np.mean(black_features, axis = 0)/np.linalg.norm(np.mean(black_features, axis = 0), 2), \n",
    "                np.mean(black_white_features, axis = 0)/np.linalg.norm(np.mean(black_white_features, axis = 0), 2), \n",
    "                np.mean(gray_features, axis = 0)/np.linalg.norm(np.mean(gray_features, axis = 0), 2), \n",
    "                np.mean(siberian_features, axis = 0)/np.linalg.norm(np.mean(siberian_features, axis = 0), 2), \n",
    "                np.mean(siamese_features, axis = 0)/np.linalg.norm(np.mean(siamese_features, axis = 0), 2), \n",
    "                np.mean(ginger_features, axis = 0)/np.linalg.norm(np.mean(ginger_features, axis = 0), 2), \n",
    "                np.mean(ginger_white_features, axis = 0)/np.linalg.norm(np.mean(ginger_white_features, axis = 0), 2),\n",
    "                np.mean(white_features, axis = 0)/np.linalg.norm(np.mean(white_features, axis = 0), 2),\n",
    "                np.mean(other_features, axis = 0)/np.linalg.norm(np.mean(other_features, axis = 0), 2)]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluation using cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred =[]\n",
    "\n",
    "for i in range(len(train_labels)):\n",
    "    y_train_pred.append(np.argmax((np.inner(train_features[i], avg_features))))\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(train_labels, y_train_pred)\n",
    "print(\"Train accuracy score: \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred =[]\n",
    "\n",
    "for i in range(len(vaL_labels)):\n",
    "    y_val_pred.append(np.argmax((np.inner(vaL_features[i], avg_features))))\n",
    "\n",
    "accuracy = accuracy_score(vaL_labels, y_val_pred)\n",
    "print(\"Validation accuracy score: \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm(vaL_labels, y_val_pred, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Estimate Equal Error Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "labels = []\n",
    "\n",
    "num_enrollment_classes = 9\n",
    "enrollment_mean_embeddings = avg_features\n",
    "trial_test_embeddings = vaL_features\n",
    "trial_test_targets = vaL_labels\n",
    "\n",
    "for i in range(num_enrollment_classes):\n",
    "    for j in range(len(trial_test_embeddings)):\n",
    "        \n",
    "        e1 = enrollment_mean_embeddings[i]\n",
    "        e2 = trial_test_embeddings[j]\n",
    "        similarity = np.inner(e1, e2)  \n",
    "        predictions.append(similarity)\n",
    "        \n",
    "        if i == trial_test_targets[j]:\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "            \n",
    "fpr, tpr, thresholds = roc_curve(labels, predictions, pos_label=1)\n",
    "f = interp1d(fpr, tpr, kind = 'nearest')\n",
    "\n",
    "x_new = np.arange(0, 1, 0.001)\n",
    "y_new = f(x_new)\n",
    "\n",
    "eer = brentq(lambda x: 1. - x - interp1d(fpr, tpr, kind = 'nearest')(x), 0., 1., xtol=1e-12, maxiter=1000)\n",
    "\n",
    "print('EER, [%]: ' + str(eer*100))\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.plot(fpr, tpr, '.', color='k', markersize=2)\n",
    "plt.plot(x_new, y_new,  '-', color='C0', linewidth=1)\n",
    "plt.plot([1, eer], [0, 1-eer], '-', color='r')\n",
    "plt.ylabel('True positive rate', size=14)\n",
    "plt.xlabel('False positive rate', size=14);\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Необработанный формат ячейки",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
